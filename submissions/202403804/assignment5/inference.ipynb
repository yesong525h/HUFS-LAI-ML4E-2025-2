{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] accelerate datasets pandas pypdf2 -U -q\n",
        "print(\" í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì—…ë°ì´íŠ¸ ì™„ë£Œ.\")\n",
        "\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from transformers.utils import is_torch_available\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Drive ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/AIHUB_DATA/'\n",
        "FINAL_MODEL_DIR = BASE_DIR + 'final_nmt_model_1500'\n",
        "PDF_FILE_PATHS = [\n",
        "    BASE_DIR + 'lec11_oop.pdf',\n",
        "    BASE_DIR + 'ml4e-lecture-week13.pdf',\n",
        "    BASE_DIR + 'NLP_11.pdf'\n",
        "]\n",
        "\n",
        "MAX_LENGTH = 50\n",
        "NUM_BEAMS = 4\n",
        "\n",
        "USER_START_PAGE = 1\n",
        "USER_END_PAGE = 5\n",
        "START_PAGE_INDEX = USER_START_PAGE - 1\n",
        "PAGE_COUNT = USER_END_PAGE - USER_START_PAGE + 1\n",
        "\n",
        "model = None\n",
        "tokenizer = None\n",
        "if os.path.isdir(FINAL_MODEL_DIR):\n",
        "    try:\n",
        "        if is_torch_available() and torch.cuda.is_available():\n",
        "            device_map = \"auto\"\n",
        "            device_info = \"GPU\"\n",
        "        else:\n",
        "            device_map = \"cpu\"\n",
        "            device_info = \"CPU\"\n",
        "\n",
        "        # í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ\n",
        "        tokenizer = AutoTokenizer.from_pretrained(FINAL_MODEL_DIR)\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(FINAL_MODEL_DIR, device_map=device_map)\n",
        "        print(f\" ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {FINAL_MODEL_DIR} (Device: {device_info})\")\n",
        "\n",
        "        # ë””ì½”ë” ì‹œì‘ í† í° ì„¤ì •\n",
        "        try:\n",
        "            KOREAN_BOS_TOKEN_ID = tokenizer.lang_code_to_id[\"ko_KR\"]\n",
        "            model.config.decoder_start_token_id = KOREAN_BOS_TOKEN_ID\n",
        "            model.generation_config.forced_bos_token_id = KOREAN_BOS_TOKEN_ID\n",
        "        except KeyError:\n",
        "            print(\" ko_KR ì–¸ì–´ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}. Drive ê²½ë¡œì™€ ì €ì¥ëœ íŒŒì¼({FINAL_MODEL_DIR})ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    print(f\" ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FINAL_MODEL_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgdEcaKQ4Gr",
        "outputId": "21f15586-2c66-4690-90bc-8ba9fa78d539"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m151.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
            "Mounted at /content/drive\n",
            " ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: /content/drive/MyDrive/AIHUB_DATA/final_nmt_model_1500 (Device: GPU)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf_range(pdf_path, start_page_index, num_pages):\n",
        "    \"\"\"\n",
        "    ì§€ì •ëœ í˜ì´ì§€ ë²”ìœ„ì˜ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    raw_text = \"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\" ì˜¤ë¥˜: PDF íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            end_page_index = start_page_index + num_pages\n",
        "\n",
        "            for i in range(start_page_index, min(end_page_index, len(reader.pages))):\n",
        "                raw_text += reader.pages[i].extract_text() or \"\"\n",
        "\n",
        "            # ê°œí–‰ ë¬¸ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ë° ë¹ˆ ì¤„ ì œê±°\n",
        "            return [raw_text]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def generate_translation(texts: list) -> list:\n",
        "    \"\"\"í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    if model is None or tokenizer is None:\n",
        "        return [\"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\"] * len(texts)\n",
        "\n",
        "    try:\n",
        "        inputs = tokenizer(texts,\n",
        "                           return_tensors=\"pt\",\n",
        "                           padding=True,\n",
        "                           truncation=True,\n",
        "                           max_length=MAX_LENGTH)\n",
        "\n",
        "        # ì…ë ¥ì„ ëª¨ë¸ì´ ìˆëŠ” ì¥ì¹˜(GPU/CPU)ë¡œ ì´ë™\n",
        "        input_ids = inputs['input_ids'].to(model.device)\n",
        "        attention_mask = inputs['attention_mask'].to(model.device)\n",
        "\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "\n",
        "            # Generation Parameters\n",
        "            max_length=MAX_LENGTH,\n",
        "            num_beams=NUM_BEAMS,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "        # ê²°ê³¼ ë””ì½”ë”©\n",
        "        translated_texts = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "        return translated_texts\n",
        "    except Exception as e:\n",
        "        print(f\"ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return [\"ì¶”ë¡  ì˜¤ë¥˜ ë°œìƒ\"] * len(texts)"
      ],
      "metadata": {
        "id": "HV5UAc1RRB1-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model is not None and tokenizer is not None:\n",
        "    all_results = []\n",
        "\n",
        "    print(f\" ë‹¤ì¤‘ PDF ì¶”ë¡  ì‹œì‘: {len(PDF_FILE_PATHS)}ê°œ íŒŒì¼ ì²˜ë¦¬ (Page {USER_START_PAGE} ~ {USER_END_PAGE})\")\n",
        "\n",
        "    for idx, pdf_path in enumerate(PDF_FILE_PATHS):\n",
        "        file_name = os.path.basename(pdf_path)\n",
        "        print(f\"\\n---  {idx+1}/{len(PDF_FILE_PATHS)} íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_name} ---\")\n",
        "\n",
        "        # extract_text_from_pdf_rangeê°€ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ë¯€ë¡œ [0] ì ‘ê·¼\n",
        "        raw_texts = extract_text_from_pdf_range(pdf_path, START_PAGE_INDEX, PAGE_COUNT)\n",
        "\n",
        "        if not raw_texts or not raw_texts[0].strip():\n",
        "             print(f\" {file_name}: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆê±°ë‚˜ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
        "             continue\n",
        "\n",
        "        raw_text = raw_texts[0]\n",
        "\n",
        "        # ê³µê²©ì ì¸ í´ë¦¬ë‹: URL, ì´ë©”ì¼, íŠ¹ìˆ˜ ë¬¸ì ì œê±°, ê°œí–‰ ë¬¸ì ê³µë°±ìœ¼ë¡œ ëŒ€ì²´\n",
        "        cleaned_text = raw_text.replace('\\n', ' ').strip() # ëª¨ë“  ê°œí–‰ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´\n",
        "        cleaned_text = re.sub(r'http\\S+|www\\S+|\\S+\\.pdf|\\S+@\\S+', '', cleaned_text, flags=re.MULTILINE).strip()\n",
        "        cleaned_text = re.sub(r'[â€¢*â€“â€”]', '', cleaned_text) # Bullet, ëŒ€ì‹œ ë“± ì œê±°\n",
        "\n",
        "        # PDF ì—°ê²°ëœ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•œ ì„ì‹œ êµ¬ë¶„ì ì‚½ì…:\n",
        "        temp_separator = ' [SEP] '\n",
        "        text_with_separators = re.sub(r'([.?!])\\s*', r'\\1' + temp_separator, cleaned_text)\n",
        "        # ì†Œë¬¸ì ë’¤ì— ëŒ€ë¬¸ìê°€ ë°”ë¡œ ì˜¤ëŠ” ê²½ìš° (ì—‰ê²¨ ë¶™ì€ í—¤ë”/ëª©ì°¨)ë¥¼ ë¬¸ì¥ ê²½ê³„ë¡œ ê°„ì£¼í•˜ì—¬ ë¶„ë¦¬\n",
        "        text_with_separators = re.sub(r'([a-z])([A-Z])', r'\\1' + temp_separator + r'\\2', text_with_separators)\n",
        "\n",
        "        # 2ê°œ ì´ìƒì˜ ì—°ì†ëœ ê³µë°±ì„ 1ê°œë¡œ ë³€í™˜\n",
        "        text_with_separators = re.sub(r'\\s{2,}', ' ', text_with_separators)\n",
        "\n",
        "        #ì„ì‹œ êµ¬ë¶„ìë¥¼ í¬í•¨í•˜ì—¬ ë¬¸ì¥ ë¶„í• \n",
        "        segments_split = [s.strip() for s in text_with_separators.split(temp_separator) if s.strip()]\n",
        "\n",
        "        cleaned_segments = []\n",
        "        MAX_TOKENS = MAX_LENGTH - 2\n",
        "\n",
        "        # ë¶„í• ëœ ë¬¸ì¥ë“¤ì„ í•„í„°ë§ ë° ê¸¸ì´ ì œí•œ\n",
        "        for sentence in segments_split:\n",
        "            # 1ì°¨ í•„í„°: ì§§ì€ ë¬¸ì¥ í•„í„°ë§ (ìµœì†Œ 5 ë‹¨ì–´ ë¯¸ë§Œì€ ì œëª©/ì£¼ì„ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)\n",
        "            if len(sentence.split()) < 5 and not sentence.endswith(('.', '?', '!')):\n",
        "                continue\n",
        "\n",
        "            # 2ì°¨ í•„í„°: ë¶ˆí•„ìš”í•œ ê¸°í˜¸ë‚˜ ìˆ˜ì‹ì´ ê³¼ë„í•œ ë¬¸ì¥ í•„í„°ë§ (ìˆ˜ì‹, ì½”ë“œ ì œê±° ëª©ì )\n",
        "            symbol_count = len(re.findall(r'[()\\[\\]\\{\\}<>\\/\\\\=\\+\\*]', sentence))\n",
        "            if symbol_count / len(sentence) > 0.15:\n",
        "                 continue\n",
        "\n",
        "            # 3ì°¨ í•„í„°: í† í° ê¸¸ì´ í™•ì¸ ë° ìë¥´ê¸°\n",
        "            tokens = tokenizer.tokenize(sentence)\n",
        "            if len(tokens) > MAX_TOKENS:\n",
        "                # 50 í† í°ì„ ë„˜ëŠ” ê²½ìš°, ìë¥´ê³  ë‹¤ì‹œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ ì œí•œ ì¤€ìˆ˜\n",
        "                tokens = tokens[:MAX_TOKENS]\n",
        "                sentence = tokenizer.convert_tokens_to_string(tokens).strip()\n",
        "\n",
        "            if sentence:\n",
        "                cleaned_segments.append(sentence)\n",
        "\n",
        "        if cleaned_segments:\n",
        "            print(f\" ì´ {len(cleaned_segments)}ê°œì˜ ìœ íš¨í•œ ë¬¸ì¥ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ì¶”ë¡  ì‹œì‘.\")\n",
        "\n",
        "            # ì¶”ë¡  ì‹¤í–‰\n",
        "            translations = generate_translation(cleaned_segments)\n",
        "\n",
        "            # ê²°ê³¼ ì €ì¥\n",
        "            for src, trg in zip(cleaned_segments, translations):\n",
        "                all_results.append({\n",
        "                    \"File\": file_name,\n",
        "                    \"Source (EN)\": src,\n",
        "                    \"Translation (KO)\": trg\n",
        "                })\n",
        "\n",
        "            print(f\" {file_name} ì¶”ë¡  ë° ê²°ê³¼ ì €ì¥ ì™„ë£Œ.\")\n",
        "\n",
        "        else:\n",
        "            print(f\" {file_name}: ì •ì œ í›„ ìœ íš¨í•œ ë¬¸ì¥ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í™•ë³´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "    if all_results:\n",
        "        df_report = pd.DataFrame(all_results)\n",
        "\n",
        "        print(f\"ìµœì¢… ì¶”ë¡ : ì´ {len(df_report)}ê°œ ì˜ˆì‹œ ({len(PDF_FILE_PATHS)}ê°œ íŒŒì¼ ì‚¬ìš©)\")\n",
        "        print(df_report.to_markdown(index=True))\n",
        "        print(\"=\"*80)\n",
        "    else:\n",
        "        print(\"\\n ëª¨ë“  íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì¶”ë¡  ì˜ˆì‹œë¥¼ í™•ë³´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"\\n ëª¨ë¸ ë¡œë“œê°€ ì‹¤íŒ¨í•˜ì—¬ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id3Q4olIVT0H",
        "outputId": "606ebe51-0c6c-46fa-820b-221c68ac92ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ë‹¤ì¤‘ PDF ì¶”ë¡  ì‹œì‘: 3ê°œ íŒŒì¼ ì²˜ë¦¬ (Page 1 ~ 5)\n",
            "\n",
            "---  1/3 íŒŒì¼ ì²˜ë¦¬ ì¤‘: lec11_oop.pdf ---\n",
            " ì´ 10ê°œì˜ ìœ íš¨í•œ ë¬¸ì¥ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ì¶”ë¡  ì‹œì‘.\n",
            " lec11_oop.pdf ì¶”ë¡  ë° ê²°ê³¼ ì €ì¥ ì™„ë£Œ.\n",
            "\n",
            "---  2/3 íŒŒì¼ ì²˜ë¦¬ ì¤‘: ml4e-lecture-week13.pdf ---\n",
            " ì´ 12ê°œì˜ ìœ íš¨í•œ ë¬¸ì¥ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ì¶”ë¡  ì‹œì‘.\n",
            " ml4e-lecture-week13.pdf ì¶”ë¡  ë° ê²°ê³¼ ì €ì¥ ì™„ë£Œ.\n",
            "\n",
            "---  3/3 íŒŒì¼ ì²˜ë¦¬ ì¤‘: NLP_11.pdf ---\n",
            " ì´ 20ê°œì˜ ìœ íš¨í•œ ë¬¸ì¥ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ì¶”ë¡  ì‹œì‘.\n",
            " NLP_11.pdf ì¶”ë¡  ë° ê²°ê³¼ ì €ì¥ ì™„ë£Œ.\n",
            "ìµœì¢… ì¶”ë¡ : ì´ 42ê°œ ì˜ˆì‹œ (3ê°œ íŒŒì¼ ì‚¬ìš©)\n",
            "|    | File                    | Source (EN)                                                                                                                                                                                               | Translation (KO)                                                                                                                                                                                                                      |\n",
            "|---:|:------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "|  0 | lec11_oop.pdf           | Yeachan Programming 2Week Contents8Classes and Objects9Inheritance and Polymorphism10File and Error Handling11Advanced Functions12Num                                                                     | ìš”ì•ˆ í”„ë¡œê·¸ë˜ë° 2ì£¼ê°„ ì»¨í…ì¸ ë“¤8í´ë˜ìŠ¤ ë° ê°ì²´ë“¤9ì¸ì‹ ë° ì˜¤ë¸Œì íŠ¸9ì¸ì‹ ë° ë‹¤í˜•ì„± ë° ë‹¤í˜•ì„±10íŒŒì¼ ë° ì˜¤ë¥˜ ì²˜ë¦¬11ë‹¨ê³„ì˜ ê¸°ëŠ¥ë“¤12N                                                                                                        |\n",
            "|  1 | lec11_oop.pdf           | Py, Pandas13Design Pattern (1)14Design Pattern (2)15Final Exam                                                                                                                                            | , pandas13ë””ìì¸ íŒ¨í„´ (1)14ë””ìì¸ íŒ¨í„´ (2)ë””ìì¸ íŒ¨í„´ (2)15Final, íŒ¨í„´ (2)15ë‹¨ê³„ì˜ ì‹¤ì‹œì˜ˆë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.                                                                                                                                 |\n",
            "|  2 | lec11_oop.pdf           | Recap.                                                                                                                                                                                                    | ì„ ë„ê¸°ëŠ” ë©°ì¹  ì „ì˜ ê¸°ë¡ì´ë‹¤.                                                                                                                                                                                                         |\n",
            "|  3 | lec11_oop.pdf           | Higher-Order Functionsmapfiltersortedclosures (function returning function)Iterators __iter__, __next__Generators & Yield infinite generatorgenerator pipeline pattern                                    | ë†’ì€ ìˆœì„œ ë§µ í•„í„° ì •ë ¬(ê¸°ëŠ¥ ë³µê·€ í•¨ìˆ˜)Itera)Itera, __ne, __ne, __ne, __ne, __ne, __ne ì—”íŠ¸ë¦¬__ ìƒì„±ê¸° ë° Yi                                                                                                                           |\n",
            "|  4 | lec11_oop.pdf           | Py: Foundation for numerical computing (arrays, matrices, â€¦)Pandas: Built on Num                                                                                                                          | Py: ìˆ˜ì¹˜ ì»´í“¨íŒ…(ì—´, í–‰ë ¬, ...)ì„ ìœ„í•œ ìˆ˜ì¹˜ ì»´í“¨íŒ…ì˜ ê¸°ë‘¥(Py: ìˆ˜ì¹˜, í–‰ë ¬, ...) íŒŒë¼ì•„íŒŒë‹¤: ë„                                                                                                                                          |\n",
            "|  5 | lec11_oop.pdf           | Py, for data manipulation and analysis Lists - Python's Basic Data Containers 5Lists can store any typeintegers, strings, objects, even other lists.                                                      | ë°ì´í„°ë¥¼ ì¡°ì‘ ë° ë¶„ì„í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸ - í‘¸í„°ì˜ ê¸°ì´ˆ ë°ì´í„° ì»¨í…Œì´ë„ˆ 5ë¦¬ìŠ¤íŠ¸ëŠ” íƒ€ì… ì¸ì, ë¬¸ìì—´, ê°ì²´, ì‹¬ì§€ì–´ ë‹¤ë¥¸ ë¦¬ìŠ¤íŠ¸ë“¤ì„ ì €ì¥í•  ìˆ˜ ìˆë‹¤.                                                                                         |\n",
            "|  6 | lec11_oop.pdf           | Indexing is simple:mylist[0]gets the first element.                                                                                                                                                       | ì¸ë±ì‹±ì€ ê°„ë‹¨í•˜ë‹¤:mylist[0]ì— ì œ1 ìš”ì†Œë¥¼ ê°€ë¦¬í‚¨ë‹¤.                                                                                                                                                                                    |\n",
            "|  7 | lec11_oop.pdf           | Lists can grow or shrink dynamically, but not optimized for numbers.                                                                                                                                      | ëª©ë¡ì€ ë™ì ìœ¼ë¡œ ì„±ì¥í•˜ê±°ë‚˜ íŒ½ì°½í•  ìˆ˜ ìˆì§€ë§Œ, ìˆ«ìì— ìµœì í™”ë˜ì§€ ì•Šë‹¤.                                                                                                                                                                  |\n",
            "|  8 | lec11_oop.pdf           | ABCDEABCDE-----FNew element!                                                                                                                                                                              | ABCDABCD-----ìƒˆë¡œìš´ ìš”ì†Œê°€ ìƒˆë¡­ë‹¤.                                                                                                                                                                                                    |\n",
            "|  9 | lec11_oop.pdf           | Array (capacity=5)Array (capacity=5Ã—2=10)Dynamic Arrays (repeated doubling)                                                                                                                               | Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra Arra |\n",
            "| 10 | ml4e-lecture-week13.pdf | Machine Learning Week 13 Deep Learning (4) Seungtaek Choi Division of Language & AI at HUFS Learning Recurrent Neural Networks                                                                            | ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸ ë¨¸                                                                                                                                                                     |\n",
            "| 11 | ml4e-lecture-week13.pdf | Sequence Modeling Sequence modeling is the task of predicting what comes next E.                                                                                                                          | í€€ìŠ¤ ëª¨ë¸ë§ í€€ìŠ¤ ëª¨ë¸ë§ì€ ë‹¤ìŒ(E)ì— ì–´ë–¤ ì¼ì´ ë°œìƒí• ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì´ë‹¤.                                                                                                                                                           |\n",
            "| 12 | ml4e-lecture-week13.pdf | g.                                                                                                                                                                                                        | g. g. . . . . . . . . . . . . .                                                                                                                                                                                                       |\n",
            "| 13 | ml4e-lecture-week13.pdf | , â€œThis morning I took my dog for a walk.                                                                                                                                                                 | ì˜¤ì „, ë³´ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ ìœ                                                                                                                                       |\n",
            "| 14 | ml4e-lecture-week13.pdf | â€ E.                                                                                                                                                                                                      | E. . . . . . . . . . . . . . . . . .                                                                                                                                                                                                  |\n",
            "| 15 | ml4e-lecture-week13.pdf | g.                                                                                                                                                                                                        | g. g. . . . . . . . . . . . . .                                                                                                                                                                                                       |\n",
            "| 16 | ml4e-lecture-week13.pdf | , given historical air quality, forecast air quality in next couple of hours.                                                                                                                             | ê³¼ê±°ì˜ ê³µê¸°ì§ˆì„ ê°ì•ˆí•  ë•Œ, ë‹¤ìŒ ëª‡ ì‹œê°„ ë™ì•ˆì˜ ê³µê¸°ì§ˆì„ ì˜ˆìƒí•œë‹¤.                                                                                                                                                                     |\n",
            "| 17 | ml4e-lecture-week13.pdf | -ai/w9w10.                                                                                                                                                                                                |                                                                                                                                                                                                                                       |\n",
            "| 18 | ml4e-lecture-week13.pdf | 3 given previous words predict the next word                                                                                                                                                              | 3ê°œì˜ ì´ì „ ë‹¨ì–´ë¥¼ ê°ê° ì˜ˆì¸¡í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œ ê²°ê³¼ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ì˜€ë‹¤.                                                                                                                                                       |\n",
            "| 19 | ml4e-lecture-week13.pdf | Sequence Modeling To model sequences, we need to: Handle variable -length sequences Track long-termdependencies Maintain information about order Share parameters across the sequence Solution: Recurrent | í€€ì‹± ì‹œí€€ìŠ¤ë¥¼ ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ì„œëŠ” ì†ëª© ê°€ë³€ - ê¸¸ì´ ì‹œí€€ìŠ¤ ì¶”ì  ì¶”ì  ì¥ê¸° ê´€ê³„ ì¶”ì  ì‹œê³„ ì¶”ì  ì¥ê¸° ê´€ê³„ ì¶”ì  ì¥ê¸° ê´€ê³„ ì¶”ì  ì‚°ì¶œ ìˆœì„œ ì „ì²´ì— ëŒ€í•œ ìˆœì„œ                                                                                 |\n",
            "| 20 | ml4e-lecture-week13.pdf | 3 A Recurrent Neural Network (RNN) Apply a recurrence relation at every time step to process a sequence: Note: the same function and set of parameters are used at every time step -ai/                   | ë°˜ë³µë§(RNN)ì€, ë‰´ëŸ´ ì‹ ê²½ë§(RNN)ì€ ì£¼ê¸°ì ìœ¼ë¡œ ë°˜ë³µì„ ì‚¬ìš©í•˜ì—¬ ë°˜ë³µì„ ë°˜ë³µí•˜ì—¬ ë°˜ë³µí•˜ì—¬ ë°˜ë³µí•˜ì—¬ ë°˜ë³µí•˜ì—¬ íë¦„ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.                                                                                                        |\n",
            "| 21 | ml4e-lecture-week13.pdf | 3 output vector input vectorâ„ğ‘¡=ğ‘“ğ‘Š(â„ğ‘¡âˆ’1,ğ‘¥ğ‘¡)cell state a function parameterized by ğ‘Šold state current input                                                                                                 | ì¶œë ¥ ë²¡í„° ì…ë ¥ ë²¡í„°ht=fW(ht-1,xt) ì…€ ìƒíƒœ ë²¡í„° Wold ìƒíƒœ ì „ë¥˜ ì…ë ¥ì— ì˜í•´ ë§¤ê°œë˜ëŠ” í•¨ìˆ˜ë¡œ íŒŒë¼ë¯¸í„°í™”ëœ í•¨ìˆ˜ì´ë‹¤.                                                                                                                      |\n",
            "| 22 | NLP_11.pdf              | Sequence Labeling(1) HUFS Fall 2025Jun-Hyung Park                                                                                                                                                         | ì‹œí€€ìŠ¤ ë¼ë²¨ë§(1) HUFS FallS Fall-Hyung Park(2025ë…„)ì— ê±¸ì¹œë‹¤.                                                                                                                                                                         |\n",
            "| 23 | NLP_11.pdf              | Lecture 11-1Sequence Labeling-Input: a sequence of n tokens/words: -Pierre Vinken, 61 years old , will join IBM â€˜s board as a nonexecutive director                                                       | 11-1ì‹œí€€ìŠ¤ ë¼ë²¨ë§-ì…ë ¥: n ê°œì˜ í† í°/ë¬¸í•­ì˜ ìˆœì„œ: -Pierre Vin, 61ì„¸ì˜ í”„ë‘ìŠ¤ê°€ ë¹„ì‹¤ì‹œì  ì£¼ë„ì „ë¬´ìë¡œì„œ IBMì˜ ì‚¬ì¥                                                                                                                      |\n",
            "| 24 | NLP_11.pdf              | 29 -Output: a sequence of n labels, such that each token/word is associated with a label: -POS-tagging: Pierre_NNPVinken_NNP,_,61_CD                                                                      |                                                                                                                                                                                                                                       |\n",
            "| 25 | NLP_11.pdf              | _NNP29_CD.                                                                                                                                                                                                | OPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOPOP                                                                                                                                        |\n",
            "| 26 | NLP_11.pdf              | _.                                                                                                                                                                                                        | _._. . . . . . . . . . . .                                                                                                                                                                                                            |\n",
            "| 27 | NLP_11.pdf              | -Named Entity Recognition: Pierre_B-PERSVinken_I-PERS,_O61_Oyears_Oold_O,_Owill_Ojoin_OIBM_B-                                                                                                             | ì´ë¦„ ì—”í‹°ìŠ¤ ì¸ì‹: Pierre_B-PERSVinken_I-PERS,_O61_Oë…„_Oold-Oold-O,_Owill_Ojoin_OIBM_B                                                                                                                                                 |\n",
            "| 28 | NLP_11.pdf              | _B-DATE29_IDATE.                                                                                                                                                                                          | BBbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb                                                                                                                                                                                       |\n",
            "| 29 | NLP_11.pdf              | _OSequence Labeling HUFS Fall 2025Jun-Hyung Park                                                                                                                                                          | _OS-Hyung Park(2025ë…„)ì— HUFS í”Œë˜ê·¸ ë¼ë²¨ë§ HUFS í”Œë˜ê·¸ë ˆì´ì…˜ì„ ë¼ë²¨ë§í•˜ëŠ” ì†Œê²¬ì„ ì œì‹œí•˜ì˜€ë‹¤.                                                                                                                                         |\n",
            "| 30 | NLP_11.pdf              | Lecture 11-2Neural Nets-Feedforward nets can only handle inputs and outputs that have a fixed size-Recurrent Neural Nets (RNNs) handle variable length sequences (as                                      | 11-2 ì‹ ê²½ë§-Feed ì—”ì§„ì€ ê³ ì •ëœ í¬ê¸°ë¥¼ ê°–ëŠ” ì…ë ¥ ë° ì¶œë ¥ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆê³  ê³ ì •ëœ í¬ê¸°ë¥¼ ê°–ëŠ” ë°˜ë³µ ì‹ ê²½ë§(RNN)ì€ ë³€ìˆ˜ ê¸¸ì´ ì‹œí€€ìŠ¤                                                                                                       |\n",
            "| 31 | NLP_11.pdf              | Nets(RNNs) HUFS Fall 2025Jun-Hyung Park                                                                                                                                                                   | (RNNs) 2018ë…„ë…„ë…„ì›”-Hyungì˜ ííííì˜ FFS Fall 2025ë…„ë…„ë…„ì˜ FFS FFS Fallê°€ ë  ì˜ˆì •ì´ë‹¤. FFS(RNNs) FFS(                                                                                                                               |\n",
            "| 32 | NLP_11.pdf              | Lecture 11-3RNNs in NLP-RNNs are used for -language modeling and generation-auto-completion and-machine translation-sequence classification (e.                                                           | NLP-RNNì—ì„œ ë‚˜ì˜¨ ê°•ì˜ 11-3RNNì€ ì–¸ì–´ ëª¨ë¸ë§ ë° ìë™-ë³µí˜¸í™” ë° ê¸°ê³„ ë²ˆì—­-ì‹œí€€ìŠ¤ ë¶„ë¥˜ ë° ìë™-ìƒì„±-ìƒì„±-ìƒì„±-ìƒì„±-ìƒì„±                                                                                                                  |\n",
            "| 33 | NLP_11.pdf              | g.                                                                                                                                                                                                        | g. g. . . . . . . . . . . . . .                                                                                                                                                                                                       |\n",
            "| 34 | NLP_11.pdf              | sentiment analysis) -sequence labeling (e.                                                                                                                                                                | ê°ì • ë¶„ì„) -ì‹œí€€ìŠ¤ ë¼ë²¨ë§(ì˜ˆë¥¼ ë“¤ì–´, ì •ì„œ ë¶„ì„) - -ì‹œí€€ìŠ¤ ë¼ë²¨ë§(e.                                                                                                                                                                   |\n",
            "| 35 | NLP_11.pdf              | g.                                                                                                                                                                                                        | g. g. . . . . . . . . . . . . .                                                                                                                                                                                                       |\n",
            "| 36 | NLP_11.pdf              | Nets(RNNs) HUFS Fall 2025Jun-Hyung Park                                                                                                                                                                   | (RNNs) 2018ë…„ë…„ë…„ì›”-Hyungì˜ ííííì˜ FFS Fall 2025ë…„ë…„ë…„ì˜ FFS FFS Fallê°€ ë  ì˜ˆì •ì´ë‹¤. FFS(RNNs) FFS(                                                                                                                               |\n",
            "| 37 | NLP_11.pdf              | Lecture 11-4RNNs in NLP-Basic RNN: Process a sequence of T inputs and/or generate a sequence of T outputs by running a [variant of a feedforward]                                                         | NLP-ë² ì´ìŠ¤ RNNì—ì„œ 11-4RNNì€ T ì…ë ¥ì˜ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê³ /ë˜ëŠ” [ë°˜ì „]ì˜ [ë³€í˜•]ì„ ì‹¤í–‰í•˜ì—¬ T ì¶œë ¥ì˜ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì‹œí€€ìŠ¤ë¥¼                                                                                                           |\n",
            "| 38 | NLP_11.pdf              | -Recurrence: The hidden state computed at the previous step (â„!                                                                                                                                           | ë°˜ë³µ: ì´ì „ ë‹¨ê³„(h)ì—ì„œ ê³„ì‚°ëœ íˆë“  ìƒíƒœ(H)ëŠ” íˆë“  ìƒíƒœë¡œ ê³„ì‚°ëœë‹¤.                                                                                                                                                                    |\n",
            "| 39 | NLP_11.pdf              | \"#) is fed into the hidden state at the current step (â„!                                                                                                                                                  | , í˜„ì¬ ë‹¨ê³„(h)ì—ì„œ ì€ë‹‰ ìƒíƒœë¡œ íë¥´ê²Œ ëœë‹¤.                                                                                                                                                                                           |\n",
            "| 40 | NLP_11.pdf              | ) With ğ»hidden units, this requires additional ğ»$parameters                                                                                                                                               | Hhid, ì´ê²ƒì€ ì¶”ê°€ì ì¸ H$parametersë¥¼ í•„ìš”ë¡œ í•œë‹¤.                                                                                                                                                                                     |\n",
            "| 41 | NLP_11.pdf              | Nets(RNNs) HUFS Fall 2025Jun-Hyung Park                                                                                                                                                                   | (RNNs) 2018ë…„ë…„ë…„ì›”-Hyungì˜ ííííì˜ FFS Fall 2025ë…„ë…„ë…„ì˜ FFS FFS Fallê°€ ë  ì˜ˆì •ì´ë‹¤. FFS(RNNs) FFS(                                                                                                                               |\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}