{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# evaluation.py (Test Set 분리 논리 반영)\n",
        "\n",
        "# ============================\n",
        "# 0. Colab 환경 설정 및 경로 정의\n",
        "# ============================\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# ⚠️ 1. Google Drive 마운트\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ⚠️ 2. PROJECT_DIR 경로 설정\n",
        "# 현재 설정: '/content/drive/MyDrive/Colab Notebooks'\n",
        "# 이 경로는 textbook_content.csv 파일과 instruction_classifier_model 폴더의 공통 상위 폴더여야 합니다.\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "# 파일 경로 정의\n",
        "CSV_FILE_PATH = os.path.join(PROJECT_DIR, \"textbook_content.csv\")\n",
        "MODEL_DIR = os.path.join(PROJECT_DIR, \"instruction_classifier_model\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 1. 라이브러리 불러오기\n",
        "# ============================\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 2. 데이터셋 정의 (InstructionDataset)\n",
        "# ============================\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, tokenizer, max_len=64):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.sentences[idx])\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 3. Test 데이터 불러오기 & 분리\n",
        "# ============================\n",
        "print(\"--- 1단계: 데이터 로드 및 Test set 분리 ---\")\n",
        "try:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding='cp949')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(CSV_FILE_PATH, encoding='utf-8')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ 오류: 데이터 파일이 없습니다. 경로를 확인하세요: {CSV_FILE_PATH}\")\n",
        "    print(\"경로 설정이 올바른지 확인해주세요.\")\n",
        "    exit()\n",
        "\n",
        "sentences = df[\"sentence\"].tolist()\n",
        "labels = df[\"label\"].tolist()\n",
        "\n",
        "# ⚠️ Test set 추출 논리 수정:\n",
        "# training.py에서 전체 데이터를 80% (Train/Val)와 20% (Test)로 나누는 것과\n",
        "# 정확히 동일한 방식으로 Test Set을 추출합니다.\n",
        "train_val_s, test_s, train_val_l, test_l = train_test_split(\n",
        "    sentences, labels, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# Test set을 최종 평가에 사용\n",
        "# (train_val_s와 train_val_l은 버립니다.)\n",
        "print(\"Test set 분리를 위해 training.py와 동일한 random_state=42를 사용했습니다.\")\n",
        "\n",
        "\n",
        "# 토크나이저 로드 (⚠️ 로컬 파일 경로 사용 및 온라인 검색 방지)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)\n",
        "\n",
        "test_dataset = InstructionDataset(test_s, test_l, tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "print(f\"Test set 크기: {len(test_dataset)}개\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 4. 모델 로드 (재현 가능한 모델 복원)\n",
        "# ============================\n",
        "print(\"\\n--- 2단계: 학습된 모델 로드 ---\")\n",
        "try:\n",
        "    # 모델 로드 (⚠️ 로컬 파일 경로 사용 및 온라인 검색 방지)\n",
        "    model = BertForSequenceClassification.from_pretrained(MODEL_DIR, local_files_only=True)\n",
        "    model.to(device)\n",
        "    print(f\"모델 로드 성공: {MODEL_DIR}/\")\n",
        "except OSError:\n",
        "    print(f\"❌ 오류: 모델 파일을 로드할 수 없습니다. 경로를 확인하세요: {MODEL_DIR}\")\n",
        "    print(\"1. training.py를 먼저 실행하여 모델을 해당 경로에 저장했는지 확인하세요.\")\n",
        "    print(\"2. MODEL_DIR 경로가 Google Drive의 실제 모델 폴더와 일치하는지 확인하세요.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 5. 최종 평가 함수\n",
        "# ============================\n",
        "def final_eval_model(model, loader):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=mask)\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            preds.extend(predictions.cpu().numpy())\n",
        "            trues.extend(labels.cpu().numpy())\n",
        "\n",
        "    return classification_report(trues, preds, digits=4)\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 6. 평가 실행\n",
        "# ============================\n",
        "print(\"\\n--- 3단계: Test set 최종 평가 수행 ---\")\n",
        "print(\"평가 지표 (Precision, Recall, F1-score, Support) :\")\n",
        "evaluation_report = final_eval_model(model, test_loader)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(evaluation_report)\n",
        "print(\"=\"*60)\n",
        "print(\"\\n평가 완료.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqQtjQBax120",
        "outputId": "a1ba2961-d231-4eca-d3e5-26b607389f17"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- 1단계: 데이터 로드 및 Test set 분리 ---\n",
            "Test set 분리를 위해 training.py와 동일한 random_state=42를 사용했습니다.\n",
            "Test set 크기: 62개\n",
            "\n",
            "--- 2단계: 학습된 모델 로드 ---\n",
            "모델 로드 성공: /content/drive/MyDrive/Colab Notebooks/instruction_classifier_model/\n",
            "\n",
            "--- 3단계: Test set 최종 평가 수행 ---\n",
            "평가 지표 (Precision, Recall, F1-score, Support) :\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8000    1.0000    0.8889        36\n",
            "           1     1.0000    0.6538    0.7907        26\n",
            "\n",
            "    accuracy                         0.8548        62\n",
            "   macro avg     0.9000    0.8269    0.8398        62\n",
            "weighted avg     0.8839    0.8548    0.8477        62\n",
            "\n",
            "============================================================\n",
            "\n",
            "평가 완료.\n"
          ]
        }
      ]
    }
  ]
}