{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yesong525h/HUFS-LAI-ML4E-2025-2/blob/assignment-5/submissions/202202605/assignment5/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ9Ow69Hnj-_",
        "outputId": "dd24c2ca-709f-48e9-e523-291ddaa3e7c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Colab 셀에 이 코드를 삽입하고 실행\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-CzFPu8nZoh",
        "outputId": "16c82db9-c1a8-43e6-fdbf-09660f727d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# inference.ipynb\n",
        "\n",
        "# =========================================================\n",
        "# 셀 1: 필수 라이브러리 설치 및 초기 설정\n",
        "# =========================================================\n",
        "!pip install transformers deep-translator -q\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Assignment5_Files/my_word_classifier\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahE-9bTund4X"
      },
      "outputs": [],
      "source": [
        "# inference.ipynb - 셀 2 수정\n",
        "\n",
        "def analyze_and_translate(text):\n",
        "\n",
        "    # 저장된 모델 불러오기 (MODEL_PATH 변수 사용)\n",
        "    try:\n",
        "        # 👈 Drive 경로 변수 사용\n",
        "        classifier = pipeline(\"text-classification\", model=MODEL_PATH, device=-1)\n",
        "    except Exception as e:\n",
        "        print(f\"🚨 모델 로드 오류: {e}\")\n",
        "        print(\"👉 training.ipynb 실행 및 Drive 경로를 확인하세요.\")\n",
        "        return\n",
        "\n",
        "    translator = GoogleTranslator(source='ko', target='es')\n",
        "\n",
        "    print(f\"▶ 입력 문장: {text}\")\n",
        "    words = text.split()\n",
        "\n",
        "    unknown_words = []\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    for word in words:\n",
        "        clean_word = word.strip(\".,?!\\\"'\")\n",
        "        if not clean_word: continue\n",
        "\n",
        "        # AI에게 물어보기\n",
        "        result = classifier(clean_word, truncation=True, max_length=32)[0]\n",
        "        label = result['label']\n",
        "\n",
        "        # 'LABEL_0(모름)'이라고 판단하면 -> 번역 실행!\n",
        "        if label == 'LABEL_0':\n",
        "            translated = translator.translate(clean_word)\n",
        "            print(f\"🚨 어려운 단어 감지: '{clean_word}' -> (스페인어: {translated})\")\n",
        "            unknown_words.append((clean_word, translated))\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    if not unknown_words:\n",
        "        print(\"✅ 모든 단어가 '아는 단어(쉬움)'로 분류되었습니다.\")\n",
        "    else:\n",
        "        print(f\"\\n=> 총 {len(unknown_words)}개의 어려운 단어를 찾았습니다.\")\n",
        "    print(\"=\" * 30 + \"\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "HpMS4qXrng0K",
        "outputId": "59a64577-1552-4f80-ef33-693debe295ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶ 입력 문장:  이 대통령은 이날 오전 내란 전담 재판부 설치법에 대한 입장을 묻는 질문에 “국회가 잘 판단해서 결정할 것으로 믿는다”면서\n",
            " “국민 여론에 따라 헌법이 부여한 권한을 입법부가 잘 행사할 것이다, 국민 주권의지를 잘 받들 것이라 생각하고 믿는다”고 말했다. 사실상 내란 전담 재판부\n",
            "  설치에 찬성하는 뜻으로 해석됐다. 이에 조 대법원장은 현재 법원이 진행 중인 재판에 신뢰를 가져달라고 한 것이다. \n",
            "------------------------------\n",
            "🚨 어려운 단어 감지: '내란' -> (스페인어: guerra civil)\n",
            "🚨 어려운 단어 감지: '받들' -> (스페인어: apoyo)\n",
            "🚨 어려운 단어 감지: '내란' -> (스페인어: guerra civil)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=> 총 3개의 어려운 단어를 찾았습니다.\n",
            "==============================\n",
            "\n",
            "▶ 입력 문장: 그러면서 “하지만 나는 역사적인 수준의 관세를 부과했고, 그 관세는 지금 엄청난 돈을 가져오고 있다. 이런 일은 과거에 한 번도 본 적이 없다. \n",
            "지금 우리는 많은 돈을 벌고 있다. 관세가 쏟아져 들어온다. 정말 많은 돈이 들어온다”라고 자화자찬했다.\n",
            "------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 모든 단어가 '아는 단어(쉬움)'로 분류되었습니다.\n",
            "==============================\n",
            "\n",
            "▶ 입력 문장: 3400만 명의 개인정보가 고스란히 노출됐지만 속 시원한 설명 한마디 들을 수 없고, 수사 중이라는 말만 기계적으로 되풀이합니다.\n",
            "------------------------------\n",
            "✅ 모든 단어가 '아는 단어(쉬움)'로 분류되었습니다.\n",
            "==============================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# 셀 3: 실제 예시 테스트 (예시 1)\n",
        "# =========================================================\n",
        "# 예시 1: 뉴스 (어려운 단어 예상)\n",
        "analyze_and_translate(''' 이 대통령은 이날 오전 내란 전담 재판부 설치법에 대한 입장을 묻는 질문에 “국회가 잘 판단해서 결정할 것으로 믿는다”면서\n",
        " “국민 여론에 따라 헌법이 부여한 권한을 입법부가 잘 행사할 것이다, 국민 주권의지를 잘 받들 것이라 생각하고 믿는다”고 말했다. 사실상 내란 전담 재판부\n",
        "  설치에 찬성하는 뜻으로 해석됐다. 이에 조 대법원장은 현재 법원이 진행 중인 재판에 신뢰를 가져달라고 한 것이다. ''')\n",
        "\n",
        "# =========================================================\n",
        "# 셀 4: 실제 예시 테스트 (예시 2)\n",
        "# =========================================================\n",
        "# 예시 2: 동화/일상 (쉬운 단어 예상)\n",
        "analyze_and_translate('''그러면서 “하지만 나는 역사적인 수준의 관세를 부과했고, 그 관세는 지금 엄청난 돈을 가져오고 있다. 이런 일은 과거에 한 번도 본 적이 없다.\n",
        "지금 우리는 많은 돈을 벌고 있다. 관세가 쏟아져 들어온다. 정말 많은 돈이 들어온다”라고 자화자찬했다.''')\n",
        "\n",
        "# =========================================================\n",
        "# 셀 5: 실제 예시 테스트 (예시 3)\n",
        "# =========================================================\n",
        "# 예시 3: 질문자님의 데이터에 있을법한 문장\n",
        "analyze_and_translate(\"\"\"이어 우원식 국회의장과 조희대 대법원장, 김민석 국무총리 등 5부 요인을 초청해 오찬을 함께하고, 저녁에는 시민단체가 주관하는 장외행사에 참석합니다.\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPXb10F/9rAHvSiZ8edk2Dk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}